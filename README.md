# conversational-ai-papers
In this seminar, we will explore the fundamentals of conversational AI, from understanding the underlying technologies to hands-on demonstrations of building chatbot applications.


מועדון קריאת מאמרים שלנו - כל ההרצאות בעיברית
| Title | Paper / Resource | Year | Why is it interesting? | Asignee | Recording | Slides |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|Large Languague Models|[Llama 2](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/), [GPT2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), [GPT4](https://arxiv.org/pdf/2303.08774.pdf)| 2023 | <details><summary>read why</summary> A review of the greatest and latest LLMs.</details> |  [@ganitk]() |[zoom](TBD)(code)|[slides](TBD) |
|Parameter-efficient fine-tuning (PEFT)||[LoRA](https://arxiv.org/pdf/2106.09685.pdf)|| 2021 | <details><summary>read why</summary> The paper that chatGPT was based on. In the paper the authors use reinforcement learning technique that encoporates human feedback as the reward. Outputs from the 1.3B parameter InstructGPT model are preferred on outputs from the 175B GPT-3 </details> |  [Presenter]() |[zoom](TBD)(code)|[slides](TBD) |
|Reinforcement learning from human feedback (RLHF)|[InstructGPT](https://arxiv.org/pdf/2203.02155.pdf)| 2022 | <details><summary>read why</summary> The paper that chatGPT was based on. In the paper the authors use reinforcement learning technique that encoporates human feedback as the reward. Outputs from the 1.3B parameter InstructGPT model are preferred on outputs from the 175B GPT-3 </details> |  [Presenter]() |[zoom](TBD)(code)|[slides](TBD) |

